# LLM Bridge Prod - 初心者向け解説

## プロジェクト概要

このリポジトリは**松尾研LLM開発コンペ2025**のための標準化されたLLM（大規模言語モデル）開発コードです。主な目的は以下の通りです：

- LLMのファインチューニング（教師あり学習）
- 強化学習（PPO: Proximal Policy Optimization）
- シングルノード・マルチノードでの分散学習
- 学習済みモデルの評価とデプロイ

## プロジェクト構造

```
llm_bridge_prod/
├── README.md                    # プロジェクト概要
├── train/                       # 学習関連のコード
│   ├── README.md               # 学習手順の概要
│   ├── README_install_conda.md # 環境構築手順
│   ├── README_single_node_SFT_PPO.md # シングルノード学習
│   ├── README_multi_node_SFT_PPO.md  # マルチノード学習
│   └── scripts/                # 学習用スクリプト
│       ├── upload_tokenizer_and_finetuned_model_to_huggingface_hub.py
│       ├── mutinode_sft/       # マルチノードSFT用
│       └── mutinode_ppo/       # マルチノードPPO用
```

## 学習の流れ

### Step 0: 環境構築
Conda環境の作成と必要なライブラリのインストール

### Step 1: シングルノード学習
- **SFT (Supervised Fine-Tuning)**: 教師ありファインチューニング
- **PPO (Proximal Policy Optimization)**: 強化学習

### Step 2: マルチノード学習
複数のGPUノードを使った分散学習

## 主要な依存関係とその目的

### 基盤環境

#### **CUDA Toolkit (12.4.1)**
- **目的**: GPU上でのディープラーニング計算を可能にする
- **機能**: GPUの並列計算能力を活用してモデルの学習を高速化
- **なぜ必要**: LLMの学習には大量の計算が必要で、CPUだけでは現実的な時間で完了できない

#### **cuDNN**
- **目的**: ディープニューラルネットワークの計算を最適化
- **機能**: 畳み込み、プーリング、正規化などの演算を高速化
- **なぜ必要**: Transformerモデルの計算を効率的に実行するため

#### **Python 3.11**
- **目的**: プログラミング言語環境
- **機能**: 機械学習ライブラリの実行基盤
- **なぜ必要**: 最新の機械学習ライブラリとの互換性を保つため

### 機械学習フレームワーク

#### **PyTorch**
- **目的**: ディープラーニングフレームワーク
- **機能**: ニューラルネットワークの構築、学習、推論
- **なぜ必要**: LLMの実装と学習の基盤となるライブラリ

#### **Transformers (Hugging Face)**
- **目的**: 事前学習済みモデルの利用
- **機能**: Llama、GPTなどの最新モデルへの簡単アクセス
- **なぜ必要**: ゼロから学習するのではなく、既存の高性能モデルをベースにファインチューニングするため

### 学習最適化ライブラリ

#### **Verl**
- **目的**: 強化学習とファインチューニングの統合フレームワーク
- **機能**: 
  - SFT（教師ありファインチューニング）の実行
  - PPO（強化学習）の実行
  - 分散学習のサポート
- **なぜ必要**: 競技で求められるSFTとPPOの両方を効率的に実行するため

#### **Apex (NVIDIA)**
- **目的**: 学習の高速化と最適化
- **機能**:
  - 混合精度学習（FP16/FP32）
  - 分散最適化アルゴリズム
  - 高速なアテンション機構
- **なぜ必要**: GPU メモリを節約し、学習速度を向上させるため

#### **Flash Attention 2**
- **目的**: メモリ効率的なアテンション計算
- **機能**: Transformerのアテンション機構を高速化
- **なぜ必要**: 長いシーケンスを扱う際のメモリ使用量を大幅に削減するため

#### **TransformerEngine**
- **目的**: Transformerモデルの最適化
- **機能**: H100 GPUでの高速計算
- **なぜ必要**: 最新のGPUアーキテクチャの性能を最大限活用するため

### 分散計算

#### **Ray**
- **目的**: 分散計算とマルチノード学習
- **機能**:
  - 複数ノード間での計算分散
  - リソース管理
  - ジョブスケジューリング
- **なぜ必要**: 大規模なモデルを複数のGPUノードで効率的に学習するため

#### **NCCL (NVIDIA Collective Communications Library)**
- **目的**: GPU間の高速通信
- **機能**: 複数GPU間でのデータ同期
- **なぜ必要**: 分散学習時にGPU間でモデルの重みを効率的に同期するため

#### **HPC-X**
- **目的**: 高性能計算用通信ライブラリ
- **機能**: ノード間の高速ネットワーク通信
- **なぜ必要**: マルチノード学習時のネットワーク通信を最適化するため

### 実験管理・モニタリング

#### **Weights & Biases (wandb)**
- **目的**: 機械学習実験の管理と可視化
- **機能**:
  - 学習過程の可視化（損失、精度など）
  - ハイパーパラメータの記録
  - 実験結果の比較
- **なぜ必要**: 学習の進捗を監視し、異なる設定での結果を比較するため

#### **TensorBoard**
- **目的**: 学習過程の可視化
- **機能**: グラフとメトリクスの表示
- **なぜ必要**: 学習の状況をリアルタイムで確認するため

### データ処理

#### **Datasets (Hugging Face)**
- **目的**: データセットの読み込みと前処理
- **機能**: 標準的なデータセット形式での効率的なデータ処理
- **なぜ必要**: GSM8Kなどの学習データを効率的に読み込むため

#### **Pandas**
- **目的**: データ分析と操作
- **機能**: 表形式データの処理
- **なぜ必要**: 学習データの前処理と分析のため

### モデル管理

#### **Hugging Face Hub**
- **目的**: モデルの保存と共有
- **機能**:
  - 学習済みモデルのアップロード
  - モデルのバージョン管理
  - チーム間でのモデル共有
- **なぜ必要**: 競技で開発したモデルを提出・共有するため

#### **Git LFS (Large File Storage)**
- **目的**: 大容量ファイルのバージョン管理
- **機能**: モデルファイルの効率的な管理
- **なぜ必要**: 数GBのモデルファイルをGitで管理するため

## 学習手法の解説

### SFT (Supervised Fine-Tuning) - 教師ありファインチューニング

**概要**: 事前学習済みのLLMを特定のタスクに適応させる手法

**プロセス**:
1. 事前学習済みモデル（例：Llama-3.2-1B-Instruct）を読み込み
2. タスク固有のデータセット（例：GSM8K数学問題）で追加学習
3. モデルがタスクに特化した回答を生成できるように調整

**使用例**: 数学問題解決、質問応答、文章要約など

### PPO (Proximal Policy Optimization) - 強化学習

**概要**: 人間のフィードバックを模倣した報酬システムでモデルを改善する手法

**プロセス**:
1. SFTで学習したモデルを基盤として使用
2. 報酬モデル（Critic）でモデルの出力を評価
3. より良い出力を生成するようにモデルを調整

**利点**: より人間らしい、有用で安全な回答を生成

## 実行環境

### シングルノード学習
- **対象**: 1ノード、8GPU（Nvidia H100）
- **用途**: 小規模なモデルや実験的な学習
- **特徴**: セットアップが簡単、デバッグしやすい

### マルチノード学習
- **対象**: 2ノード、16GPU（Nvidia H100）
- **用途**: 大規模なモデルや本格的な学習
- **特徴**: より高速な学習、大きなバッチサイズ

## 使用例：GSM8Kデータセットでの学習

### データセット
- **GSM8K**: 小学校レベルの数学文章問題
- **形式**: 問題文と解答のペア
- **目的**: 数学的推論能力の向上

### 学習フロー
1. **データ準備**: GSM8Kデータセットをダウンロード
2. **SFT実行**: 数学問題の解き方を学習
3. **PPO実行**: より良い解答を生成するように調整
4. **モデル変換**: Hugging Face形式に変換
5. **アップロード**: Hugging Face Hubに公開

## トラブルシューティング

### よくある問題

#### GPU メモリ不足
- **原因**: バッチサイズが大きすぎる
- **解決策**: `micro_batch_size_per_gpu`を小さくする

#### 分散学習の通信エラー
- **原因**: ネットワーク設定の問題
- **解決策**: `NCCL_SOCKET_IFNAME`を正しく設定

#### 環境変数の設定ミス
- **原因**: モジュールの読み込み順序
- **解決策**: `module reset`してから正しい順序で読み込み

### ベストプラクティス

1. **段階的な学習**: まずシングルノードで動作確認してからマルチノードに移行
2. **リソース監視**: GPU使用率とメモリ使用量を常に監視
3. **実験管理**: wandbで学習過程を記録し、結果を比較
4. **バックアップ**: 重要なチェックポイントは複数箇所に保存

## 参考リンク

- [サーバ利用手順](https://docs.google.com/document/d/16KKkFM8Sbqx0wgcCY4kBKR6Kik01T-jn892e_y67vbM/edit?tab=t.0)
- [Hugging Face トークン発行](https://huggingface.co/settings/tokens)
- [Weights & Biases](https://wandb.ai/)

## まとめ

このプロジェクトは、最新のLLM学習技術を統合した包括的なフレームワークです。各依存関係は特定の目的を持ち、全体として効率的で高性能なLLM学習環境を構築しています。初心者の方は、まずシングルノードでの学習から始めて、徐々に高度な機能を習得することをお勧めします。
